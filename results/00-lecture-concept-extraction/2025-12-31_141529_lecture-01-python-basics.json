{
  "usecase": {
    "name": "Concepts Extraction from Lecture Transcript",
    "folder": "sample-usecases/00-lecture-concept-extraction",
    "data_file": "sample-usecases\\00-lecture-concept-extraction\\data\\lecture-01-python-basics.txt",
    "ground_truth_file": "sample-usecases\\00-lecture-concept-extraction\\ground-truth\\lecture-01-concepts.csv"
  },
  "prompts": {
    "analysis": {
      "transformation_type": "Temporal segmentation and concept extraction from timestamped lecture transcripts",
      "key_fields": [
        "concept",
        "start_time",
        "end_time"
      ],
      "quality_indicators": [
        "All segments between 2-7 minutes duration (3-6 minutes ideal)",
        "Sequential numbering with descriptive concept names in XX_Title_Case_Format",
        "Gapless coverage (each end_time matches next start_time)",
        "Natural pedagogical boundaries between concepts",
        "Complete transcript coverage from start to finish",
        "Descriptive concept names (3-7 words) that accurately reflect content"
      ],
      "comparison_strategy": "Compare segment count, duration compliance, naming convention adherence, temporal coverage gaps, and boundary alignment between output and ground truth"
    },
    "task_prompt": "You are an expert educational content curator. Your task is to extract distinct teaching concepts from a lecture transcript and segment them into bite-sized video clips.\n\n**INPUT:** A lecture transcript with timestamps in [HH:MM:SS] format.\n\n**YOUR TASK:** Identify self-contained teaching concepts and output them as a CSV with three columns: concept, start_time, end_time.\n\n**REQUIREMENTS:**\n\n1. **Duration Constraints:**\n   - Each segment must be 2-7 minutes long\n   - Ideal length is 3-6 minutes\n   - Segments under 2 minutes or over 7 minutes are violations\n\n2. **Concept Naming:**\n   - Format: `XX_Concept_Name_In_Title_Case`\n   - Number sequentially starting from 01\n   - Use underscores, no spaces\n   - Be descriptive but concise (3-7 words)\n   - Accurately reflect the teaching content\n\n3. **Coverage:**\n   - Cover the ENTIRE lecture with NO GAPS\n   - Each segment's end_time must equal the next segment's start_time\n   - Start from the lecture beginning, end at the lecture conclusion\n   - Exclude breaks but don't create gaps (merge around them)\n\n4. **Boundaries:**\n   - Cut at natural transition points between concepts\n   - Each segment should be self-contained and make sense independently\n   - Respect pedagogical flow (don't split explanations mid-thought)\n\n5. **Edge Cases:**\n   - Q&A sections: merge with preceding concept or create separate segment if substantial\n   - Tangential stories: include with the relevant concept\n   - Mid-lecture breaks: exclude duration but maintain continuous timestamps\n   - Repeated references: keep with the current concept being taught\n\n**OUTPUT FORMAT:**\n```csv\nconcept,start_time,end_time\n01_Introduction_to_Topic_Name,00:00:00,00:04:32\n02_Core_Concept_Definition,00:04:32,00:08:15\n```\n\n**Time Format:** HH:MM:SS (e.g., 00:04:32)\n\nProvide ONLY the CSV output, no additional text or explanations.",
    "judge_prompt": "You are evaluating the quality of lecture concept extraction against a ground truth reference. Compare the candidate output to the ground truth CSV and score based on the criteria below.\n\n**INPUTS:**\n- Ground Truth CSV: The reference segmentation\n- Candidate Output CSV: The LLM's extraction to evaluate\n- Original Transcript: The source material\n\n**EVALUATION CRITERIA:**\n\n**1. DURATION COMPLIANCE (30 points)**\n- Check each segment duration (end_time - start_time)\n- CRITICAL VIOLATION: Segment under 2 minutes OR over 7 minutes (-5 points each)\n- MINOR: Segment outside ideal 3-6 minute range but within 2-7 minutes (-1 point each)\n- Calculate: Total segments compliant / Total segments \u00d7 30\n\n**2. COVERAGE COMPLETENESS (25 points)**\n- First segment must start at lecture beginning (00:00:00 or within 5 seconds)\n- Last segment must end at lecture conclusion (compare to ground truth end time \u00b110 seconds)\n- Check for GAPS: Any gap where segment[n].end_time \u2260 segment[n+1].start_time (-5 points per gap)\n- Check for OVERLAPS: segment[n].end_time > segment[n+1].start_time (-5 points per overlap)\n- Deduct points from 25 based on violations\n\n**3. CONCEPT NAMING QUALITY (20 points)**\n- Format compliance: XX_Title_Case_With_Underscores (-2 points per violation)\n- Sequential numbering: Must be 01, 02, 03... with no skips (-3 points per error)\n- Descriptiveness: Names should be 3-7 words and accurately reflect content (-2 points for vague/inaccurate names)\n- Compare semantic similarity to ground truth concept names (if highly divergent, -3 points)\n\n**4. SEGMENTATION ACCURACY (25 points)**\n- Compare segment count: Ground truth has 8 segments\n  - If candidate has 6-10 segments: Full points\n  - If candidate has 4-5 or 11-12 segments: -5 points (under/over-segmented)\n  - If candidate has <4 or >12 segments: -15 points (severely wrong granularity)\n- Boundary alignment: Compare candidate boundaries to ground truth (\u00b130 seconds tolerance is acceptable)\n  - Major misalignment (>2 minutes off): -3 points per boundary\n  - Minor misalignment (30sec-2min off): -1 point per boundary\n\n**SCORING CALCULATION:**\n1. Start with 100 points\n2. Apply all penalties from each category\n3. Ensure category scores don't go below 0\n4. Sum all category scores for final score (0-100)\n\n**OUTPUT FORMAT:**\nProvide a JSON evaluation:\n```json\n{\n  \"duration_compliance\": {\"score\": X, \"violations\": [\"list\"], \"details\": \"explanation\"},\n  \"coverage_completeness\": {\"score\": X, \"violations\": [\"list\"], \"details\": \"explanation\"},\n  \"concept_naming\": {\"score\": X, \"violations\": [\"list\"], \"details\": \"explanation\"},\n  \"segmentation_accuracy\": {\"score\": X, \"violations\": [\"list\"], \"details\": \"explanation\"},\n  \"total_score\": X,\n  \"quality_tier\": \"Excellent|Good|Acceptable|Poor\",\n  \"summary\": \"Brief overall assessment\"\n}\n```\n\n**QUALITY TIERS:**\n- Excellent (90-100): All segments 2-7 min, complete coverage, accurate names, natural boundaries\n- Good (75-89): 1-2 minor violations, mostly accurate, near-complete coverage\n- Acceptable (60-74): 3-5 violations, some issues but usable output\n- Poor (<60): 6+ violations OR major gaps OR severely wrong segmentation",
    "rubric": {
      "critical_requirements": [
        {
          "name": "duration_constraints",
          "description": "All segments must be between 2-7 minutes in duration",
          "derived_from": "Ground truth shows 8 segments all within acceptable range; use case explicitly states 2 min minimum, 7 min maximum",
          "penalty_per_violation": 5
        },
        {
          "name": "gapless_coverage",
          "description": "No gaps or overlaps between consecutive segments; each end_time must equal next start_time",
          "derived_from": "Ground truth shows perfect continuity: 00:02:42\u219200:02:42, 00:07:15\u219200:07:15, etc. Use case states 'gapless' as key requirement",
          "penalty_per_violation": 5
        },
        {
          "name": "complete_transcript_coverage",
          "description": "First segment starts at lecture beginning, last segment ends at lecture conclusion",
          "derived_from": "Ground truth starts at 00:00:00 and covers full lecture duration; use case requires 'full transcript coverage'",
          "penalty_per_violation": 10
        },
        {
          "name": "naming_convention",
          "description": "Format must be XX_Title_Case_With_Underscores, sequentially numbered from 01",
          "derived_from": "Ground truth demonstrates consistent format: 01_Introduction_and_Variables_Overview, 02_Data_Types_Numbers_and_Strings, etc.",
          "penalty_per_violation": 2
        }
      ],
      "compliance_checks": [
        {
          "check": "segment_too_short",
          "condition": "Any segment duration < 2 minutes",
          "severity": "CRITICAL",
          "penalty": 5
        },
        {
          "check": "segment_too_long",
          "condition": "Any segment duration > 7 minutes",
          "severity": "CRITICAL",
          "penalty": 5
        },
        {
          "check": "temporal_gap",
          "condition": "segment[n].end_time \u2260 segment[n+1].start_time (gap exists)",
          "severity": "CRITICAL",
          "penalty": 5
        },
        {
          "check": "temporal_overlap",
          "condition": "segment[n].end_time > segment[n+1].start_time",
          "severity": "CRITICAL",
          "penalty": 5
        },
        {
          "check": "missing_start_coverage",
          "condition": "First segment start_time > 00:00:05",
          "severity": "HIGH",
          "penalty": 10
        },
        {
          "check": "missing_end_coverage",
          "condition": "Last segment end_time more than 10 seconds before lecture conclusion",
          "severity": "HIGH",
          "penalty": 10
        },
        {
          "check": "incorrect_naming_format",
          "condition": "Concept name doesn't follow XX_Title_Case_Format",
          "severity": "MEDIUM",
          "penalty": 2
        },
        {
          "check": "non_sequential_numbering",
          "condition": "Numbering skips or doesn't start at 01",
          "severity": "MEDIUM",
          "penalty": 3
        },
        {
          "check": "vague_concept_name",
          "condition": "Concept name is not descriptive (too short, generic, or inaccurate)",
          "severity": "MEDIUM",
          "penalty": 2
        },
        {
          "check": "wrong_granularity",
          "condition": "Segment count differs significantly from expected range (ground truth: 8 segments, acceptable: 6-10)",
          "severity": "HIGH",
          "penalty": 5
        },
        {
          "check": "boundary_misalignment",
          "condition": "Segment boundaries differ from ground truth by >2 minutes",
          "severity": "MEDIUM",
          "penalty": 3
        },
        {
          "check": "invalid_csv_format",
          "condition": "Output is not valid CSV or missing required columns",
          "severity": "CRITICAL",
          "penalty": 50
        }
      ],
      "weights": {
        "accuracy": 40,
        "format": 20,
        "compliance": 40
      },
      "scoring_instructions": "Start with 100 points. Evaluate each compliance check and apply penalties. Accuracy (40 points) covers segmentation accuracy and boundary alignment. Format (20 points) covers CSV structure and naming conventions. Compliance (40 points) covers duration constraints and coverage completeness. Sum penalties within each category, ensuring no category goes below 0. Final score = 100 - total_penalties. Quality tier: Excellent (90-100), Good (75-89), Acceptable (60-74), Poor (<60)."
    }
  },
  "results": [
    {
      "model_name": "openai/gpt-4o",
      "task_name": "concepts_extraction_from_lecture_transcript",
      "output": "/* chunk 1 */\n```csv\nconcept,start_time,end_time\n01_Introduction_to_Python_Basics,00:00:00,00:02:42\n02_Variables_and_Assignment,00:02:42,00:06:48\n03_Data_Types_and_Operations,00:06:48,00:10:25\n04_Comparison_and_Logical_Operators,00:10:25,00:13:52\n05_If_Statements_and_Conditionals,00:13:52,00:17:48\n06_Loops_and_Iterables,00:17:48,00:22:05\n07_Common_Pitfalls_and_Summary,00:22:05,00:25:35\n08_QA_and_Conclusion,00:25:35,00:27:02\n```",
      "input_tokens": 4827,
      "output_tokens": 175,
      "total_tokens": 5002,
      "cost_usd": 0.0138,
      "billed_cost_usd": 0.0138175,
      "latency_ms": 4148.717900039628,
      "timestamp": "2025-12-31 14:14:49.944074",
      "generation_id": "gen-1767212086-cWFrk75GTb7BhC9AMemN",
      "provider": null,
      "status": "success",
      "error": null
    },
    {
      "model_name": "anthropic/claude-sonnet-4",
      "task_name": "concepts_extraction_from_lecture_transcript",
      "output": "/* chunk 1 */\n```csv\nconcept,start_time,end_time\n01_Introduction_And_Variables_Basics,00:00:00,00:02:42\n02_Python_Data_Types_Overview,00:02:42,00:07:15\n03_Operators_And_Type_Conversion,00:07:15,00:11:20\n04_Conditional_Statements_And_If_Else,00:11:20,00:15:10\n05_For_Loops_And_Iteration,00:15:10,00:19:42\n06_While_Loops_And_Loop_Control,00:19:42,00:21:55\n07_Common_Pitfalls_And_Course_Wrap_Up,00:21:55,00:27:02\n```",
      "input_tokens": 5282,
      "output_tokens": 192,
      "total_tokens": 5474,
      "cost_usd": 0.0187,
      "billed_cost_usd": 0.018726,
      "latency_ms": 4717.796099954285,
      "timestamp": "2025-12-31 14:14:50.501353",
      "generation_id": "gen-1767212086-sW2zu1uqbwxvZTo2D55W",
      "provider": null,
      "status": "success",
      "error": null
    }
  ],
  "scores": [
    {
      "model_evaluated": "openai/gpt-4o",
      "accuracy_score": 75,
      "format_score": 95,
      "compliance_score": 88,
      "overall_score": 84,
      "violations": [
        "Segment 02 duration: 4:06 minutes - acceptable but boundary misaligned (ground truth ends at 00:07:15, candidate at 00:06:48, difference of 27 seconds)",
        "Segment 03 duration: 3:37 minutes - acceptable but boundary misaligned (ground truth starts at 00:07:15, candidate at 00:06:48; ground truth ends at 00:10:05, candidate at 00:10:25, difference of 20 seconds)",
        "Segment 04 duration: 3:27 minutes - acceptable but boundary misaligned (ground truth ends at 00:13:28, candidate at 00:13:52, difference of 24 seconds)",
        "Segment 05 duration: 3:56 minutes - acceptable but boundary misaligned (ground truth ends at 00:17:08, candidate at 00:17:48, difference of 40 seconds)",
        "Segment 06 duration: 4:17 minutes - acceptable but boundary misaligned (ground truth ends at 00:20:15, candidate at 00:22:05, difference of 1:50 minutes)",
        "Segment 07 duration: 3:30 minutes - acceptable but boundary misaligned (ground truth ends at 00:23:30, candidate at 00:25:35, difference of 2:05 minutes)",
        "Concept name '01_Introduction_to_Python_Basics' differs semantically from ground truth '01_Introduction_and_Variables_Overview'",
        "Concept name '02_Variables_and_Assignment' differs from ground truth '02_Data_Types_Numbers_and_Strings' - appears to cover different content scope",
        "Concept name '03_Data_Types_and_Operations' differs from ground truth '03_Type_Checking_and_Conversion' - appears to cover different content scope",
        "Concept name '07_Common_Pitfalls_and_Summary' differs from ground truth '07_Practical_Example_Number_Guessing_Game' - significantly different content",
        "Concept name '08_QA_and_Conclusion' differs from ground truth '08_Summary_and_Homework_Assignment' - different content focus"
      ],
      "reasoning": "DURATION COMPLIANCE (88/100): All 8 segments fall within the 2-7 minute range. Segment durations: 2:42, 4:06, 3:37, 3:27, 3:56, 4:17, 3:30, 1:27. Segment 08 (1:27) is under the 2-minute minimum (-5 points). Segment 01 (2:42) is outside ideal 3-6 range but within acceptable 2-7 range (-1 point). Remaining segments are within ideal range. Score: 30 - 5 - 1 = 24/30 = 80%. Adjusted to 88 considering overall compliance. COVERAGE COMPLETENESS (25/25): First segment starts at 00:00:00 (correct). Last segment ends at 00:27:02 (matches ground truth exactly). No gaps detected - all end times match subsequent start times perfectly. No overlaps. Full coverage achieved. CONCEPT NAMING QUALITY (16/20): Format compliance is excellent - all use XX_Title_Case_With_Underscores format. Sequential numbering is correct (01-08). However, several concept names differ semantically from ground truth, suggesting different content interpretation or boundary placement. Deductions: -2 points for semantic divergence in segments 01, 02, 03, 07, 08 (total -4 points). Score: 16/20 = 80%. SEGMENTATION ACCURACY (19/25): Both ground truth and candidate have 8 segments (full points for count). However, boundary alignment shows significant deviations: Segments 06 and 07 have major misalignments (>1:50 minutes off from ground truth boundaries), suggesting different pedagogical chunking decisions (-3 points each = -6 points). Score: 25 - 6 = 19/25 = 76%. TOTAL CALCULATION: Duration (24/30) + Coverage (25/25) + Naming (16/20) + Segmentation (19/25) = 84/100. Quality tier: Good (75-89). The output demonstrates strong format compliance and complete coverage, but shows moderate boundary misalignment and content interpretation differences compared to ground truth.",
      "timestamp": "2025-12-31 14:15:11.280597"
    },
    {
      "model_evaluated": "anthropic/claude-sonnet-4",
      "accuracy_score": 72,
      "format_score": 95,
      "compliance_score": 71,
      "overall_score": 75,
      "violations": [
        "Segment 03 (00:07:15-00:11:20) duration 4:05 - acceptable but boundary misaligned by ~1 minute from ground truth",
        "Segment 04 (00:11:20-00:15:10) duration 3:50 - boundary misaligned by ~1.5 minutes from ground truth segment 04 start (00:10:05)",
        "Segment 05 (00:15:10-00:19:42) duration 4:32 - boundary misaligned by ~2 minutes from ground truth segment 06 start (00:17:08)",
        "Segment 06 (00:19:42-00:21:55) duration 2:13 - acceptable but not in ground truth structure",
        "Segment count: 7 vs ground truth 8 - slight under-segmentation",
        "Missing explicit segment for 'Practical_Example_Number_Guessing_Game' (00:20:15-00:23:30 in ground truth)",
        "Concept name 'Operators_And_Type_Conversion' merges two distinct ground truth concepts",
        "Major boundary misalignment: Segment 04 starts at 00:11:20 vs ground truth 00:10:05 (1:15 off)"
      ],
      "reasoning": "DURATION COMPLIANCE (21/30): All 7 segments fall within 2-7 minute range. Segment 1: 2:42 (ideal), Segment 2: 4:33 (ideal), Segment 3: 4:05 (ideal), Segment 4: 3:50 (ideal), Segment 5: 4:32 (ideal), Segment 6: 2:13 (acceptable but below ideal), Segment 7: 5:07 (ideal). No critical violations. Minor penalty for segment 6 being slightly short of ideal range (-1 point). Score: 29/30. COVERAGE COMPLETENESS (25/25): Starts at 00:00:00 (correct), ends at 00:27:02 (correct), no gaps or overlaps detected. All segments connect properly. Full points. CONCEPT NAMING (18/20): Format compliance good - all use XX_Title_Case_With_Underscores. Sequential numbering 01-07 correct. Names are descriptive but some semantic divergence from ground truth: 'Operators_And_Type_Conversion' appears to merge ground truth segments 03 and 04 content. 'While_Loops_And_Loop_Control' not explicitly in ground truth. Minor penalties for semantic alignment (-2 points). SEGMENTATION ACCURACY (15/25): Ground truth has 8 segments, candidate has 7 (-2 points for slight under-segmentation). Boundary alignment issues: Segment 3 end at 00:11:20 vs ground truth segment 04 start at 00:10:05 (1:15 misalignment, -1 point). Segment 4 boundaries significantly off from ground truth structure (-3 points). Segment 5 start at 00:15:10 vs ground truth segment 06 start at 00:17:08 (1:58 misalignment, -1 point). Missing distinct 'Number_Guessing_Game' segment (-3 points). Total segmentation score: 15/25. TOTAL: 21+25+18+15 = 79. Adjusted to 75 considering overall alignment with ground truth structure.",
      "timestamp": "2025-12-31 14:15:29.495564"
    }
  ],
  "statistics": {
    "total_cost": 0.03,
    "total_tokens": 10476,
    "total_input_tokens": 10109,
    "total_output_tokens": 367,
    "total_evaluations": 2,
    "avg_cost_per_eval": 0.015,
    "avg_tokens_per_eval": 5238,
    "cost_by_model": {
      "openai/gpt-4o": {
        "cost": 0.0138,
        "input_tokens": 4827,
        "output_tokens": 175,
        "evaluations": 1
      },
      "anthropic/claude-sonnet-4": {
        "cost": 0.0187,
        "input_tokens": 5282,
        "output_tokens": 192,
        "evaluations": 1
      }
    }
  }
}